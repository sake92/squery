# squery

Simple SQL queries in Scala 3

Inspired by [simplesql](https://github.com/jodersky/simplesql) and [doobie](https://tpolecat.github.io/doobie/).

---
You can find some examples:
- in squery [tests](https://github.com/sake92/squery/blob/main/squery/test/src/ba/sake/squery/SquerySuite.scala).  
- in the [examples](/examples) folder.

## Setup

```scala
// sbt
libraryDependencies ++= Seq(
  ivy"ba.sake::squery:0.0.6"
)

// mill
def ivyDeps = Agg(
  ivy"ba.sake::squery:0.0.6"
)
```

## Context

First, we need to initialize a `SqueryContext` with a standard JDBC `DataSource`:
```scala
val ds = com.zaxxer.hikari.HikariDataSource()
ds.setJdbcUrl(..)
ds.setUsername(..)
ds.setPassword(..)

ctx = new SqueryContext(ds)
```

Then we can run queries inside it:
```scala
ctx.run {
    // queries go here!
}
```
or if you want to run them in a transaction:
```scala
ctx.runTransaction {
    // queries go here!
}
```

There is an implicit JDBC connection under the cover,  
thanks to scala 3's context functions! <3

---
---

## Reading data

Queries are written as plain SQL strings.

### Reading one-column values

```scala
import ba.sake.squery.*

def customersIds: List[Int] = ctx.run {
  sql"SELECT id FROM customers".readValues[Int]()
}
```

There are also varations that return a single result, depending if you want an `Option[T]` or `T`:
```scala
sql"SELECT ...".readValueOpt : Option[T]
sql"SELECT ...".readValue : T
```

---

### Reading multi-column values
Here we do care about column names, so we read these into case classes:
```scala
import ba.sake.squery.*

case class Customer(id: Int, name: String) derives SqlReadRow

def customers: List[Customer] = ctx.run {
  sql"SELECT id, name FROM customers".readRows[Customer]()
}
```

There are also varations that return a single result, depending if you want an `Option[T]` or `T`:
```scala
sql"SELECT ...".readRowOpt : Option[T]
sql"SELECT ...".readRow : T
```

---

### Reading joined tables

These are usually a bit involved in all SQL libraries/frameworks.  
In most of scala ones they use tuples, but here we compose case classes.  
Case class variables like `c: Customer` are expected to have corresponding column names like `c.id` and `c.name` in the query.  
The final query is a composition of `Customer` and `Phone`, so it maps nicely in your head, it is easier to read and manipulate.  
You could have additional columns like a `COUNT`/`SUM` or whatever you need in `CustomerWithPhone` query result. :)

```scala
import ba.sake.squery.*

case class Customer(id: Int, name: String) derives SqlReadRow
case class Phone(id: Int, number: String) derives SqlReadRow

case class CustomerWithPhone(c: Customer, p: Phone) derives SqlReadRow

def customerwithPhones: List[CustomerWithPhone] = ctx.run {
  sql"""
    SELECT c.id, c.name,
           p.id, p.number
    FROM customers c
    JOIN phones p ON p.customer_id = c.id
  """.readRows[CustomerWithPhone]()
}
```

### Reading outer (LEFT/RIGHT) joined tables

Only thing you need to do is to make the optional table field `Option[T]`:
```scala
case class CustomerWithPhoneOpt(c: Customer, p: Option[Phone]) derives SqlReadRow

def customerwithPhones: List[CustomerWithPhone] = ctx.run {
  sql"SELECT ...".readRows[CustomerWithPhoneOpt]()
}
```

It would return `None` for `p: Option[Phone]` if all its returned columns are `NULL`.

---
---

## Inserting data

### Simple insert
Simplest method just inserts the rows and returns number of affected rows.
```scala
def insertCustomer: Int = ctx.run {
  sql"INSERT INTO customers(name) VALUES('my_customer')".insert()
}
```

---
### Insert and return generated keys
This method inserts the rows and returns autogenerated keys (`AUTOINCREMENT`, `SERIAL` etc).
```scala
def insertCustomer: Int = ctx.run {
  sql"INSERT INTO customers(name) VALUES('my_customer')".insertReturningGenKey[Int]()
}
```

---
### Insert returning inserted values
This method inserts the rows and returns columns you want from inserted rows.  
This is not supported by all databases unfortunately.
```scala
def insertCustomers: List[Customer] = ctx.run {
  sql"""
    INSERT INTO customers(name)
    VALUES ('abc'), ('def'), ('ghi')
    RETURNING id, name
  """.insertReturningRows[Customer]()
}
```
Here in one query you can both insert + get the row you inserted.  

---
---

## Updating
You can do arbitrary SQL commands here.  
The most common one is `UPDATE`:
```scala
// returns number of affected rows
def updateCustomers: Int = ctx.run {
  sql"""
    UPDATE customers
    SET name = 'whatever'
    WHERE name LIKE 'xyz_%'
  """.update()
}
```

But of course you can do others:
```scala
def createTable: Unit = ctx.run {
  sql"""
    CREATE TABLE customers(
      id SERIAL PRIMARY KEY,
      name VARCHAR
    )
  """.update()
}
```

---
---

## Interpolating values
You can use any JDBC-writable value in your queries.  

```scala
val customerId = 123
val phoneNumber = "123456"
sql"""
  INSERT INTO phones(customer_id, number)
  VALUES($customerId, $phoneNumber)
""".insert()
```

Actually, the type of value needs to have a `SqlWrite[T]` typeclass instance implemented.  
Please contribute back to squery when you find something is missing! :)


## Dynamic queries

Of course, in the real world, you will need to compose queries dynamically at runtime.  
A common example on the web is when you have a sorting functionality.  

```scala
enum SortCustomersField:
    case id, name

def customers(sortBy: SortCustomersField): List[Customer] = ctx.run {
  val query = sql"SELECT id, name FROM customers" ++ sortBy(sortBy)
  query.readRows[Customer]()
}

def sortBy(sortBy: SortCustomersField): Query = sortBy match
  case SortCustomersField.id   => sql"ORDER BY id DESC"
  case SortCustomersField.name => sql"ORDER BY name DESC"
```
