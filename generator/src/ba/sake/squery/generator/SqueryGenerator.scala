package ba.sake.squery.generator

import java.sql.{Array => _, _}
import scala.util._
import org.apache.commons.text.CaseUtils
import com.typesafe.scalalogging.Logger
import java.io.File

class SqueryGenerator(config: SqueryGeneratorConfig = SqueryGeneratorConfig.Default) {
  private val logger = Logger(getClass.getName)

  private val Preamble = "/* DO NOT EDIT MANUALLY! Automatically generated by squery generator */"

  def generateString(dbDef: DbDef, schemaNames: Seq[String]): String =
    schemaNames
      .map { schemaName =>
        dbDef.schemas.find(_.name == schemaName) match {
          case Some(schemaDef) =>
            logger.info(s"Started generating schema '${schemaName}'")
            val (imports, enumDefsScala, tableDefsScala) = generateSchema(schemaDef, dbName = dbDef.name)
            val res =
              s"""|${Preamble}
                  |${imports}
                  |
                  |${enumDefsScala.mkString("\n")}
                  |
                  |${tableDefsScala.mkString("\n")}
                  |""".stripMargin
            logger.info(s"Finished generating schema '${schemaName}'")
            res
          case None =>
            throw new RuntimeException(s"Schema '${schemaName}' does not exist")
        }
      }
      .mkString("\n")

  def generateFiles(dbDef: DbDef, schemaConfigs: Seq[SchemaConfig]): Unit =
    schemaConfigs.foreach { schemaConfig =>
      dbDef.schemas.find(_.name == schemaConfig.name) match {
        case Some(schemaDef) =>
          logger.info(s"Started generating schema '${schemaConfig.name}' into '${schemaConfig.baseFolder}'")
          val packagePath = os.RelPath(schemaConfig.basePackage.replaceAll("\\.", "/"))
          val (imports, modelDefsScala, daoDefsScala) = generateSchema(schemaDef, dbName = dbDef.name)
          modelDefsScala.foreach { modelFile =>
            val modelFileWithImports =
              s"""|${Preamble}
                  |package ${schemaConfig.basePackage}.models
                  |
                  |${imports}
                  |
                  |${modelFile.content}
                  |""".stripMargin
            os.write.over(
              schemaConfig.baseFolder / packagePath / "models" / modelFile.baseName,
              modelFileWithImports,
              createFolders = true
            )
          }
          daoDefsScala.foreach { daoFile =>
            val daoFileWithImports =
              s"""|${Preamble}
                  |package ${schemaConfig.basePackage}.daos
                  |
                  |${imports}
                  |import ${schemaConfig.basePackage}.models.*
                  |
                  |${daoFile.content}
                  |""".stripMargin
            os.write.over(
              schemaConfig.baseFolder / packagePath / "daos" / daoFile.baseName,
              daoFileWithImports,
              createFolders = true
            )
          }
          logger.info(s"Finished generating schema '${schemaConfig.name}'")
        case None =>
          throw new RuntimeException(s"Schema '${schemaConfig.name}' does not exist")
      }
    }

  // (imports, models, repos)
  private def generateSchema(
      schemaDef: SchemaDef,
      dbName: String
  ): (String, Seq[GeneratedFile], Seq[GeneratedFile]) = {
    val enumDefs = schemaDef.tables.flatMap {
      _.columnDefs.map(_.scalaType).collect { case e: ColumnType.Enumeration =>
        e
      }
    }
    val enumFiles = enumDefs.map { enumDef =>
      val enumCaseDefs = enumDef.values.map { enumDefCaseValue =>
        s"    case ${enumDefCaseValue.safeIdentifier}"
      }
      val enumName = transformName(enumDef.name, config.typeNameMapper)
      val contents =
        s"""|enum ${enumName} derives SqlRead, SqlWrite:
            |${enumCaseDefs.mkString("\n")}
            |""".stripMargin
      GeneratedFile(s"${enumName}.scala", contents)
    }

    val tableFiles = schemaDef.tables.map { tableDef =>
      val columnDefsScala = tableDef.columnDefs.map { columnDef =>
        val safeTypeName = getSafeTypeName(columnDef.scalaType, config.typeNameMapper)
        val tpe = if (columnDef.metadata.isNullable) s"Option[${safeTypeName}]" else safeTypeName
        s"    ${columnDef.metadata.name.safeIdentifier}: ${tpe}"
      }
      val columnNamesScala = tableDef.columnDefs.map { columnDef =>
        s"""  inline val ${columnDef.metadata.name.safeIdentifier} = "${columnDef.metadata.name.safeIdentifier}""""
      }
      val prefixedColumnNamesScala = tableDef.columnDefs.map { columnDef =>
        s"""prefix + ${columnDef.metadata.name.safeIdentifier}"""
      }
      val caseClassName = transformName(tableDef.name, config.typeNameMapper) + config.rowTypeSuffix
      val (pkValue, pkTypeDef) = // TODO handle empty
        if (tableDef.pkColumns.length == 1) {
          val pkCol = tableDef.pkColumns.head
          (s"${pkCol.metadata.name}", s"type PK = ${pkCol.scalaType.name}")
        } else {
          val (pkColExprs, pkColDefs) = tableDef.pkColumns.map { pkCol =>
            (pkCol.metadata.name, s"${pkCol.metadata.name}: ${pkCol.scalaType.name}")
          }.unzip
          (s"${caseClassName}.PK(${pkColExprs.mkString(", ")})", s"case class PK(${pkColDefs.mkString(", ")})")
        }
      val contents =
        s"""|case class ${caseClassName}(
            |${columnDefsScala.mkString(",\n")}
            |) derives SqlReadRow {
            |  def pk: ${caseClassName}.PK = ${pkValue}
            |}
            |
            |object ${caseClassName} {
            |  inline val TableName = "${tableDef.schema}.${tableDef.name}"
            |
            |${columnNamesScala.mkString("\n")}
            |
            |  inline val * = prefixed("")
            |
            |  transparent inline def prefixed(inline prefix: String) =
            |    ${prefixedColumnNamesScala.mkString(""" + ", " + """)}
            |
            |  ${pkTypeDef}
            |}
            |""".stripMargin
      GeneratedFile(s"${caseClassName}.scala", contents)
    }

    val daoFiles = schemaDef.tables.map { tableDef =>
      val caseClassName = transformName(tableDef.name, config.typeNameMapper) + config.rowTypeSuffix
      val daoClassName = transformName(tableDef.name, config.typeNameMapper) + "CrudDao"
      val findByIdWhereExpr = if (tableDef.pkColumns.isEmpty) {
        // TODO throw or skip when no pks
        ???
      } else if (tableDef.pkColumns.length == 1) {
        s"${tableDef.pkColumns.head.metadata.name} = $${id}"
      } else
        tableDef.pkColumns
          .map { pkCol =>
            s"${pkCol.metadata.name} = $${id.${pkCol.metadata.name}}"
          }
          .mkString(" AND ")
      val contents =
        s"""|trait ${daoClassName} {
            |  def countAll(): DbAction[Int] =
            |    sql"SELECT COUNT(*) FROM $${${caseClassName}.TableName}".readValue()
            |
            |  def findAll(): DbAction[Seq[${caseClassName}]] =
            |    sql"SELECT $${${caseClassName}.*} FROM $${${caseClassName}.TableName}".readRows()
            |
            |  def findById(id: ${caseClassName}.PK): DbAction[${caseClassName}] =
            |    sql"SELECT $${${caseClassName}.*} FROM $${${caseClassName}.TableName} WHERE ${findByIdWhereExpr}".readRow()
            |}
            |
            |object ${daoClassName} extends ${daoClassName} {
            |
            |}
            |""".stripMargin
      GeneratedFile(s"${daoClassName}.scala", contents)
    }

    val squeryDbPackage =
      if (dbName.contains("postgres")) "postgres"
      else if (dbName.contains("mysql")) "mysql"
      else if (dbName.contains("mariadb")) "mariadb"
      else if (dbName.contains("oracle")) "oracle"
      else if (dbName.contains("h2")) "h2"
      else throw new RuntimeException(s"Unknown database type $dbName")

    val imports =
      s"""|import java.time.*
          |import java.util.UUID
          |import ba.sake.squery.{*, given}
          |import ba.sake.squery.${squeryDbPackage}.given
          |import ba.sake.squery.read.SqlRead
          |import ba.sake.squery.write.SqlWrite
          |""".stripMargin

    (imports, enumFiles ++ tableFiles, daoFiles)
  }

  private def transformName(str: String, nameMapper: NameMapper): String =
    nameMapper match {
      case NameMapper.Noop      => str
      case NameMapper.CamelCase => CaseUtils.toCamelCase(str, true, '_')
    }

  private def getSafeTypeName(tpe: ColumnType, nameMapper: NameMapper): String = tpe match {
    case ColumnType.Predefined(name)              => name
    case ColumnType.Enumeration(enumName, values) => transformName(enumName, nameMapper).safeIdentifier
    case ColumnType.Unknown(originalName)         => s"<UNKNOWN> // ${originalName}"
  }

  implicit class StrOps(str: String) {
    def safeIdentifier: String =
      if (SqueryGenerator.ReservedScalaKeywords(str) || str.contains("-"))
        s"`${str}`"
      else str
  }

}

object SqueryGenerator {
  // https://www.scala-lang.org/files/archive/spec/3.4/01-lexical-syntax.html#regular-keywords
  private val ReservedScalaKeywords = s"""
    abstract  case      catch     class     def       do        else
    enum      export    extends   false     final     finally   for
    given     if        implicit  import    lazy      match     new
    null      object    override  package   private   protected return
    sealed    super     then      throw     trait     true      try
    type      val       var       while     with      yield
    :         =         <-        =>        <:        >:        #
    @         =>>       ?=>
    """.split("\\s+").map(_.trim).toSet
}

case class SchemaConfig(
    name: String,
    baseFolder: os.Path,
    basePackage: String
)

sealed abstract class NameMapper
object NameMapper {
  case object Noop extends NameMapper
  case object CamelCase extends NameMapper
}

// TODO camelCase identifiers??
case class SqueryGeneratorConfig(
    typeNameMapper: NameMapper,
    rowTypeSuffix: String
)

object SqueryGeneratorConfig {
  val Default: SqueryGeneratorConfig =
    SqueryGeneratorConfig(typeNameMapper = NameMapper.CamelCase, rowTypeSuffix = "Row")
}

case class GeneratedFile(
    baseName: String,
    content: String
)
